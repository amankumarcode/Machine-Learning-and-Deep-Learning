{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_VGG16.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L-Pe3WXPJK9",
        "colab_type": "code",
        "outputId": "bfeef408-6589-45b9-e8f9-2eda39a3ece4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "from keras.layers.core import Lambda\n",
        "from keras import backend as K\n",
        "from keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2L6YjmBQm0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvgvj-18Q1fz",
        "colab_type": "code",
        "outputId": "8fdb0e33-b89a-4599-c587-6b654ad9ca89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LnEtxJqTvR3",
        "colab_type": "code",
        "outputId": "599408bf-b615-45e3-8a5f-9ff91cc4653a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1fSAcngTyT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=x_train - np.mean(x_train) / x_train.std()\n",
        "x_test=x_test - np.mean(x_test) / x_test.std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjd0VL19UjHO",
        "colab_type": "code",
        "outputId": "9e836153-dbff-417f-c1e6-7413d6762bb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',padding = 'same', input_shape=(32,32,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3),padding = 'same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.3))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3),padding = 'same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3),padding = 'same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3),padding = 'same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3),padding = 'same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3),padding = 'same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3),padding = 'same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3),padding = 'same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3),padding = 'same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.3))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3),padding = 'same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3),padding = 'same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3),padding = 'same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR1TXPOTaBIK",
        "colab_type": "code",
        "outputId": "90f50b54-8a44-4c43-c19c-d4fd322b0157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 50\n",
        "learning_rate = 1e-3\n",
        "lr_decay = 1e-6\n",
        "sgd = optimizers.SGD(lr=learning_rate, decay=lr_decay, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7YcAeMw6Cd1",
        "colab_type": "code",
        "outputId": "a2923d16-ff22-45fa-c38b-0f27e01bb504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=batch_size, nb_epoch=epochs, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 151s 3ms/step - loss: 2.2458 - acc: 0.2401\n",
            "50000/50000 [==============================] - 151s 3ms/step - loss: 2.2458 - acc: 0.2401\n",
            "Epoch 2/50\n",
            "   32/50000 [..............................] - ETA: 2:38 - loss: 2.1005 - acc: 0.2188Epoch 2/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 1.6956 - acc: 0.3686\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 1.6956 - acc: 0.3686\n",
            "Epoch 3/50\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 1.4889 - acc: 0.4541\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 1.4889 - acc: 0.4541\n",
            "Epoch 4/50\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 1.3225 - acc: 0.5215\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 1.3225 - acc: 0.5215\n",
            "Epoch 5/50\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 1.2081 - acc: 0.5665\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 1.2081 - acc: 0.5665\n",
            "Epoch 6/50\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 1.1044 - acc: 0.6075\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 1.1044 - acc: 0.6075\n",
            "Epoch 7/50\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 1.0149 - acc: 0.6421\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 1.0149 - acc: 0.6421\n",
            "Epoch 8/50\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.9385 - acc: 0.6701\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.9385 - acc: 0.6701\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 148s 3ms/step - loss: 0.8640 - acc: 0.7014\n",
            "50000/50000 [==============================] - 148s 3ms/step - loss: 0.8640 - acc: 0.7014\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 148s 3ms/step - loss: 0.8022 - acc: 0.7255\n",
            "50000/50000 [==============================] - 148s 3ms/step - loss: 0.8022 - acc: 0.7255\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 148s 3ms/step - loss: 0.7499 - acc: 0.7436\n",
            "50000/50000 [==============================] - 148s 3ms/step - loss: 0.7499 - acc: 0.7436\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 147s 3ms/step - loss: 0.7146 - acc: 0.7566\n",
            "50000/50000 [==============================] - 147s 3ms/step - loss: 0.7146 - acc: 0.7566\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 149s 3ms/step - loss: 0.6682 - acc: 0.7731\n",
            "50000/50000 [==============================] - 149s 3ms/step - loss: 0.6682 - acc: 0.7731\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 148s 3ms/step - loss: 0.6339 - acc: 0.7848\n",
            "50000/50000 [==============================] - 148s 3ms/step - loss: 0.6339 - acc: 0.7848\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.6084 - acc: 0.7933\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.6084 - acc: 0.7933\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 144s 3ms/step - loss: 0.5795 - acc: 0.8041\n",
            "50000/50000 [==============================] - 144s 3ms/step - loss: 0.5795 - acc: 0.8041\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 144s 3ms/step - loss: 0.5423 - acc: 0.8169\n",
            "50000/50000 [==============================] - 144s 3ms/step - loss: 0.5423 - acc: 0.8169\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 147s 3ms/step - loss: 0.5227 - acc: 0.8232\n",
            "50000/50000 [==============================] - 147s 3ms/step - loss: 0.5227 - acc: 0.8232\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.5028 - acc: 0.8295\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.5028 - acc: 0.8295\n",
            "Epoch 20/50\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.4811 - acc: 0.8388\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.4811 - acc: 0.8388\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.4606 - acc: 0.8447\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.4606 - acc: 0.8447\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.4424 - acc: 0.8508\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.4424 - acc: 0.8508\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.4261 - acc: 0.8551\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.4261 - acc: 0.8551\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.4034 - acc: 0.8619\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.4034 - acc: 0.8619\n",
            "Epoch 25/50\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.3857 - acc: 0.8683\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.3857 - acc: 0.8683\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.3743 - acc: 0.8741\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.3743 - acc: 0.8741\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.3577 - acc: 0.8790\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.3577 - acc: 0.8790\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 148s 3ms/step - loss: 0.3474 - acc: 0.8842\n",
            "50000/50000 [==============================] - 148s 3ms/step - loss: 0.3474 - acc: 0.8842\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 148s 3ms/step - loss: 0.3295 - acc: 0.8900\n",
            "50000/50000 [==============================] - 148s 3ms/step - loss: 0.3295 - acc: 0.8900\n",
            "Epoch 30/50\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.3212 - acc: 0.8919\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.3212 - acc: 0.8919\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.3048 - acc: 0.8978\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.3048 - acc: 0.8978\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.2878 - acc: 0.9020\n",
            "50000/50000 [==============================] - 146s 3ms/step - loss: 0.2878 - acc: 0.9020\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 150s 3ms/step - loss: 0.2797 - acc: 0.9046\n",
            "50000/50000 [==============================] - 150s 3ms/step - loss: 0.2797 - acc: 0.9046\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 147s 3ms/step - loss: 0.2730 - acc: 0.9060\n",
            "50000/50000 [==============================] - 147s 3ms/step - loss: 0.2730 - acc: 0.9060\n",
            "Epoch 35/50\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 148s 3ms/step - loss: 0.2578 - acc: 0.9130\n",
            "50000/50000 [==============================] - 148s 3ms/step - loss: 0.2578 - acc: 0.9130\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 148s 3ms/step - loss: 0.2526 - acc: 0.9135\n",
            "50000/50000 [==============================] - 148s 3ms/step - loss: 0.2526 - acc: 0.9135\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 147s 3ms/step - loss: 0.2329 - acc: 0.9234\n",
            "50000/50000 [==============================] - 147s 3ms/step - loss: 0.2329 - acc: 0.9234\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "23616/50000 [=============>................] - ETA: 1:17 - loss: 0.2315 - acc: 0.9212Buffered data was truncated after reaching the output size limit.Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUnnN91Z6LOJ",
        "colab_type": "code",
        "outputId": "b04c04da-213b-4796-b1e0-2b5df851cebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 15,001,418\n",
            "Trainable params: 14,991,946\n",
            "Non-trainable params: 9,472\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeEjJHkCTVli",
        "colab_type": "code",
        "outputId": "86acf6a0-4c33-49ba-f8ea-8ea00a9bbe4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5758374200105667, 0.8604]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RVYUrRpVAF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}